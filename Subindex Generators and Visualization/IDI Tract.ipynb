{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5828f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "from shapely.geometry import mapping\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f24f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch intersections using Overpass API\n",
    "def fetch_intersections_overpass(polygon, year):\n",
    "    \"\"\"\n",
    "    Fetches intersections using Overpass API, including implicit intersections where multiple ways share nodes.\n",
    "    \"\"\"\n",
    "    polygon = gpd.GeoSeries([polygon], crs=\"EPSG:3857\").to_crs(epsg=4326).iloc[0]\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:60][date:\"{year}-01-01T00:00:00Z\"];\n",
    "    (\n",
    "      node[highway]({miny},{minx},{maxy},{maxx});\n",
    "      way[highway]({miny},{minx},{maxy},{maxx});\n",
    "    );\n",
    "    out body;\n",
    "    >;\n",
    "    out skel qt;\n",
    "    \"\"\"\n",
    "    response = requests.get(overpass_url, params={'data': query})\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "        return 0\n",
    "\n",
    "    data = response.json().get('elements', [])\n",
    "    node_degree = defaultdict(int)\n",
    "\n",
    "    for element in data:\n",
    "        if element['type'] == 'way' and 'nodes' in element:\n",
    "            for node_id in element['nodes']:\n",
    "                node_degree[node_id] += 1  # Track node usage across ways\n",
    "\n",
    "    # Count intersections: nodes with degree > 1\n",
    "    intersection_count = sum(1 for count in node_degree.values() if count > 1)\n",
    "    return intersection_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19ba569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IDI for a given GeoJSON input, year, and output prefix\n",
    "def calculate_idi(input_geojson, output_prefix, year, aggregate_file):\n",
    "    data = gpd.read_file(input_geojson)\n",
    "    data = data.to_crs(epsg=3857)  # Project to EPSG:3857 for area calculations\n",
    "    areas = data.geometry.area\n",
    "    geoids = data[\"GEOID\"] if \"GEOID\" in data.columns else data[\"geoid\"]\n",
    "\n",
    "    intersection_counts = []\n",
    "    for idx, polygon in enumerate(data.geometry):\n",
    "        print(f\"Processing polygon {idx + 1}/{len(data.geometry)} for year {year}...\")\n",
    "        intersection_count = fetch_intersections_overpass(polygon, year)\n",
    "        intersection_counts.append(intersection_count)\n",
    "\n",
    "    # Calculate intersection density\n",
    "    intersection_density = [count / area if area > 0 else 0 for count, area in zip(intersection_counts, areas)]\n",
    "\n",
    "    # Normalize IDI\n",
    "    max_density = max(intersection_density) if intersection_density else 1\n",
    "    idi = [density / max_density for density in intersection_density]\n",
    "\n",
    "    # Add fields to GeoDataFrame\n",
    "    data[\"Intersection Count\"] = intersection_counts\n",
    "    data[\"Polygon Area\"] = areas\n",
    "    data[\"Intersection Density\"] = intersection_density\n",
    "    data[\"IDI\"] = [0] * len(data)  # Placeholder for IDI\n",
    "    data[\"Coordinates\"] = data.geometry.apply(lambda geom: mapping(geom)[\"coordinates\"])\n",
    "    data['Polygon Area'] = data.geometry.area\n",
    "\n",
    "    # Convert back to EPSG:4326 for output\n",
    "    data = data.to_crs(epsg=4326)\n",
    "    \n",
    "    columns_to_keep = [\"GEOID\", \"Intersection Count\", \"Intersection Density\", \"IDI\", \"Polygon Area\", \"Coordinates\", \"geometry\"]\n",
    "    data = data[columns_to_keep]\n",
    "    \n",
    "    geoidandyear = data[\"GEOID\"] + \"+\" + str(year)\n",
    "    # Append to aggregate file\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Intersection Density\": data[\"Intersection Density\"]\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode='w', header=True, index=False)\n",
    "\n",
    "    # Save outputs as GeoJSON and CSV\n",
    "    geojson_file = f\"{output_prefix}_{year}_IDI.geojson\"\n",
    "    csv_file = f\"{output_prefix}_{year}_IDI.csv\"\n",
    "    data.to_file(geojson_file, driver=\"GeoJSON\")\n",
    "    data.drop(columns=\"geometry\").to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Processed {year}. Outputs saved to '{geojson_file}' and '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869a7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing polygon 1/10 for year 2013...\n",
      "Processing polygon 2/10 for year 2013...\n",
      "Processing polygon 3/10 for year 2013...\n",
      "Processing polygon 4/10 for year 2013...\n",
      "Processing polygon 5/10 for year 2013...\n",
      "Processing polygon 6/10 for year 2013...\n",
      "Processing polygon 7/10 for year 2013...\n",
      "Processing polygon 8/10 for year 2013...\n",
      "Processing polygon 9/10 for year 2013...\n",
      "Processing polygon 10/10 for year 2013...\n",
      "Processed 2013. Outputs saved to 'tracts_2013_IDI.geojson' and 'tracts_2013_IDI.csv'.\n",
      "Processing polygon 1/10 for year 2017...\n",
      "Processing polygon 2/10 for year 2017...\n",
      "Processing polygon 3/10 for year 2017...\n",
      "Processing polygon 4/10 for year 2017...\n",
      "Processing polygon 5/10 for year 2017...\n",
      "Processing polygon 6/10 for year 2017...\n",
      "Processing polygon 7/10 for year 2017...\n",
      "Processing polygon 8/10 for year 2017...\n",
      "Processing polygon 9/10 for year 2017...\n",
      "Processing polygon 10/10 for year 2017...\n",
      "Processed 2017. Outputs saved to 'tracts_2017_IDI.geojson' and 'tracts_2017_IDI.csv'.\n",
      "Processing polygon 1/10 for year 2022...\n",
      "Processing polygon 2/10 for year 2022...\n",
      "Processing polygon 3/10 for year 2022...\n",
      "Processing polygon 4/10 for year 2022...\n",
      "Processing polygon 5/10 for year 2022...\n",
      "Processing polygon 6/10 for year 2022...\n",
      "Processing polygon 7/10 for year 2022...\n",
      "Processing polygon 8/10 for year 2022...\n",
      "Processing polygon 9/10 for year 2022...\n",
      "Processing polygon 10/10 for year 2022...\n",
      "Processed 2022. Outputs saved to 'tracts_2022_IDI.geojson' and 'tracts_2022_IDI.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Census Tracts\n",
    "calculate_idi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=\"2013\",\n",
    "    aggregate_file=\"IDI_tract_all.csv\"\n",
    ")\n",
    "calculate_idi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=\"2017\",\n",
    "    aggregate_file=\"IDI_tract_all.csv\"\n",
    ")\n",
    "calculate_idi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=\"2022\",\n",
    "    aggregate_file=\"IDI_tract_all.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23fc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
