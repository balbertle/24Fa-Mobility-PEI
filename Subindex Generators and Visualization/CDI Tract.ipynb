{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f423413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "from shapely.geometry import mapping, Point\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527a8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_commercial_data(polygon, year):\n",
    "    \"\"\"\n",
    "    Fetches commercial data using Overpass API for a given polygon and year.\n",
    "    Args:\n",
    "        polygon (shapely.geometry.Polygon): Polygon representing the geographic area.\n",
    "        year (int): Year for which data is being fetched.\n",
    "    Returns:\n",
    "        list: A list of shapely Point objects representing commercial points of interest.\n",
    "    \"\"\"\n",
    "    # Transform the polygon to EPSG:4326\n",
    "    polygon = gpd.GeoSeries([polygon], crs=\"EPSG:3857\").to_crs(epsg=4326).iloc[0]\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:60][date:\"{year}-01-01T00:00:00Z\"];\n",
    "    (\n",
    "      node[\"shop\"]({miny},{minx},{maxy},{maxx});\n",
    "      node[\"amenity\"~\"restaurant|cafe|bank|school|cinema\"]({miny},{minx},{maxy},{maxx});\n",
    "      node[\"leisure\"~\"park|sports_centre|stadium\"]({miny},{minx},{maxy},{maxx});\n",
    "    );\n",
    "    out body;\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(overpass_url, params={'data': query})\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching data from Overpass API: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    elements = response.json().get('elements', [])\n",
    "    return [\n",
    "        Point(element['lon'], element['lat'])\n",
    "        for element in elements if 'lat' in element and 'lon' in element\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b415a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cdi(input_geojson, output_prefix, year, aggregate_file):\n",
    "    \"\"\"\n",
    "    Calculates Commercial Density Index (CDI) for a given GeoJSON input file, year, and outputs the results.\n",
    "    Args:\n",
    "        input_geojson (str): Path to the input GeoJSON file containing tract polygons.\n",
    "        output_prefix (str): Prefix for output files.\n",
    "        year (int): Year for which CDI is calculated.\n",
    "        aggregate_file (str): File path to append aggregate results.\n",
    "    \"\"\"\n",
    "    # Load GeoJSON data\n",
    "    data = gpd.read_file(input_geojson).to_crs(epsg=3857)\n",
    "    \n",
    "    # Prepare storage for commercial counts and densities\n",
    "    commercial_counts = []\n",
    "    commercial_densities = []\n",
    "    \n",
    "    # Process each polygon\n",
    "    print(f\"Processing year {year}...\")\n",
    "    all_poi_points = []\n",
    "    for idx, polygon in enumerate(data[\"geometry\"]):\n",
    "        print(f\"  Fetching commercial data for polygon {idx + 1}/{len(data)}...\")\n",
    "        try:\n",
    "            poi_points = fetch_commercial_data(polygon, year)\n",
    "            all_poi_points.extend(poi_points)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing polygon {idx + 1}: {e}\")\n",
    "    \n",
    "    # Create a GeoDataFrame of all points of interest\n",
    "    all_poi_gdf = gpd.GeoDataFrame(geometry=all_poi_points, crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    \n",
    "    # Perform spatial join to count POIs within each polygon\n",
    "    joined = gpd.sjoin(all_poi_gdf, data, how=\"inner\", predicate=\"within\")\n",
    "    counts = joined.groupby(joined.index_right).size().reindex(data.index, fill_value=0)\n",
    "    \n",
    "    # Calculate densities\n",
    "    densities = counts.values / data.geometry.area\n",
    "    max_density = densities.max() if densities.max() > 0 else 1\n",
    "    cdi = densities / max_density\n",
    "    \n",
    "    # Add results to the GeoDataFrame\n",
    "    data[\"Commercial Count\"] = counts.values\n",
    "    data['Polygon Area'] = data.geometry.area\n",
    "    data[\"Commercial Density\"] = densities\n",
    "    data[\"Coordinates\"] = data.geometry.apply(lambda geom: mapping(geom)[\"coordinates\"])\n",
    "    data[\"CDI\"] = cdi\n",
    "    \n",
    "    columns_to_keep = [\"GEOID\", \"Commercial Count\", \"Commercial Density\", \"CDI\", \"Polygon Area\", \"Coordinates\", \"geometry\"]\n",
    "    data = data[columns_to_keep]\n",
    "    \n",
    "    # Save results to GeoJSON and CSV\n",
    "    geojson_output = f\"{output_prefix}_{year}_CDI.geojson\"\n",
    "    csv_output = f\"{output_prefix}_{year}_CDI.csv\"\n",
    "    data.to_crs(epsg=4326).to_file(geojson_output, driver=\"GeoJSON\")\n",
    "    data.drop(columns=[\"geometry\"]).to_csv(csv_output, index=False)\n",
    "    \n",
    "    # Append aggregate results\n",
    "    geoidandyear = data[\"GEOID\"] + \"+\" + str(year)\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Commercial Density\": densities,\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode=\"w\", header=True, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {geojson_output} and {csv_output}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae69d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2013...\n",
      "  Fetching commercial data for polygon 1/30...\n",
      "  Fetching commercial data for polygon 2/30...\n",
      "  Fetching commercial data for polygon 3/30...\n",
      "  Fetching commercial data for polygon 4/30...\n",
      "  Fetching commercial data for polygon 5/30...\n",
      "  Fetching commercial data for polygon 6/30...\n",
      "  Fetching commercial data for polygon 7/30...\n",
      "  Fetching commercial data for polygon 8/30...\n",
      "  Fetching commercial data for polygon 9/30...\n",
      "  Fetching commercial data for polygon 10/30...\n",
      "  Fetching commercial data for polygon 11/30...\n",
      "  Fetching commercial data for polygon 12/30...\n",
      "  Fetching commercial data for polygon 13/30...\n",
      "  Fetching commercial data for polygon 14/30...\n",
      "  Fetching commercial data for polygon 15/30...\n",
      "  Fetching commercial data for polygon 16/30...\n",
      "  Fetching commercial data for polygon 17/30...\n",
      "  Fetching commercial data for polygon 18/30...\n",
      "  Fetching commercial data for polygon 19/30...\n",
      "  Fetching commercial data for polygon 20/30...\n",
      "  Fetching commercial data for polygon 21/30...\n",
      "  Fetching commercial data for polygon 22/30...\n",
      "  Fetching commercial data for polygon 23/30...\n",
      "  Fetching commercial data for polygon 24/30...\n",
      "  Fetching commercial data for polygon 25/30...\n",
      "  Fetching commercial data for polygon 26/30...\n",
      "  Fetching commercial data for polygon 27/30...\n",
      "  Fetching commercial data for polygon 28/30...\n",
      "  Fetching commercial data for polygon 29/30...\n",
      "  Fetching commercial data for polygon 30/30...\n",
      "Results saved to tracts_2013_CDI.geojson and tracts_2013_CDI.csv.\n",
      "Processing year 2017...\n",
      "  Fetching commercial data for polygon 1/30...\n",
      "  Fetching commercial data for polygon 2/30...\n",
      "  Fetching commercial data for polygon 3/30...\n",
      "  Fetching commercial data for polygon 4/30...\n",
      "  Fetching commercial data for polygon 5/30...\n",
      "  Fetching commercial data for polygon 6/30...\n",
      "  Fetching commercial data for polygon 7/30...\n",
      "  Fetching commercial data for polygon 8/30...\n",
      "  Fetching commercial data for polygon 9/30...\n",
      "  Fetching commercial data for polygon 10/30...\n",
      "  Fetching commercial data for polygon 11/30...\n",
      "  Fetching commercial data for polygon 12/30...\n",
      "  Fetching commercial data for polygon 13/30...\n",
      "  Fetching commercial data for polygon 14/30...\n",
      "  Fetching commercial data for polygon 15/30...\n",
      "  Fetching commercial data for polygon 16/30...\n",
      "  Fetching commercial data for polygon 17/30...\n",
      "  Fetching commercial data for polygon 18/30...\n",
      "  Fetching commercial data for polygon 19/30...\n",
      "  Fetching commercial data for polygon 20/30...\n",
      "  Fetching commercial data for polygon 21/30...\n",
      "  Fetching commercial data for polygon 22/30...\n",
      "  Fetching commercial data for polygon 23/30...\n",
      "  Fetching commercial data for polygon 24/30...\n",
      "  Fetching commercial data for polygon 25/30...\n",
      "  Fetching commercial data for polygon 26/30...\n",
      "  Fetching commercial data for polygon 27/30...\n",
      "  Fetching commercial data for polygon 28/30...\n",
      "  Fetching commercial data for polygon 29/30...\n",
      "  Fetching commercial data for polygon 30/30...\n",
      "Results saved to tracts_2017_CDI.geojson and tracts_2017_CDI.csv.\n",
      "Processing year 2022...\n",
      "  Fetching commercial data for polygon 1/30...\n",
      "  Fetching commercial data for polygon 2/30...\n",
      "  Fetching commercial data for polygon 3/30...\n",
      "  Fetching commercial data for polygon 4/30...\n",
      "  Fetching commercial data for polygon 5/30...\n",
      "  Fetching commercial data for polygon 6/30...\n",
      "  Fetching commercial data for polygon 7/30...\n",
      "  Fetching commercial data for polygon 8/30...\n",
      "  Fetching commercial data for polygon 9/30...\n",
      "  Fetching commercial data for polygon 10/30...\n",
      "  Fetching commercial data for polygon 11/30...\n",
      "  Fetching commercial data for polygon 12/30...\n",
      "  Fetching commercial data for polygon 13/30...\n",
      "  Fetching commercial data for polygon 14/30...\n",
      "  Fetching commercial data for polygon 15/30...\n",
      "  Fetching commercial data for polygon 16/30...\n",
      "  Fetching commercial data for polygon 17/30...\n",
      "  Fetching commercial data for polygon 18/30...\n",
      "  Fetching commercial data for polygon 19/30...\n",
      "  Fetching commercial data for polygon 20/30...\n",
      "  Fetching commercial data for polygon 21/30...\n",
      "  Fetching commercial data for polygon 22/30...\n",
      "  Fetching commercial data for polygon 23/30...\n",
      "  Fetching commercial data for polygon 24/30...\n",
      "  Fetching commercial data for polygon 25/30...\n",
      "  Fetching commercial data for polygon 26/30...\n",
      "  Fetching commercial data for polygon 27/30...\n",
      "  Fetching commercial data for polygon 28/30...\n",
      "  Fetching commercial data for polygon 29/30...\n",
      "  Fetching commercial data for polygon 30/30...\n",
      "Results saved to tracts_2022_CDI.geojson and tracts_2022_CDI.csv.\n"
     ]
    }
   ],
   "source": [
    "# Census Tracts\n",
    "calculate_cdi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=2013,\n",
    "    aggregate_file=\"CDI_tract_all.csv\"\n",
    ")\n",
    "\n",
    "calculate_cdi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=2017,\n",
    "    aggregate_file=\"CDI_tract_all.csv\"\n",
    ")\n",
    "calculate_cdi(\n",
    "    input_geojson=\"tracts.geojson\",  # Replace with your census tract GeoJSON file\n",
    "    output_prefix=\"tracts\",\n",
    "    year=2022,\n",
    "    aggregate_file=\"CDI_tract_all.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f8fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
