{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185b2c43-819a-4098-8f88-580a9c421b64",
   "metadata": {
    "id": "185b2c43-819a-4098-8f88-580a9c421b64"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8191d59f-c299-4b82-82ae-8043c54e0403",
   "metadata": {
    "id": "8191d59f-c299-4b82-82ae-8043c54e0403"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_blockgroup_population(census_gdf, census_api_key, year, output_file, csv_output_file, aggregate_file):\n",
    "    \"\"\"\n",
    "    Retrieves population data for block groups based on a given year and saves the processed data to a file.\n",
    "\n",
    "    Parameters:\n",
    "        census_gdf (GeoDataFrame): The GeoDataFrame containing the geometries for the census block groups.\n",
    "        census_api_key (str): The Census API key.\n",
    "        year (int): The year for which the data is retrieved (e.g., 2013, 2022).\n",
    "        output_file (str): The filename where the processed data will be saved.\n",
    "        csv_output_file (str): The filename for saving the processed CSV data.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the processed data to the specified files.\n",
    "    \"\"\"\n",
    "    # Check if the API key is provided\n",
    "    if not census_api_key:\n",
    "        raise ValueError(\"API key must be provided as the 'census_api_key' parameter.\")\n",
    "\n",
    "    # Gets state and county FIPS codes\n",
    "    state_fips = census_gdf.STATEFP[0]\n",
    "    county_fips = census_gdf.COUNTYFP.unique()\n",
    "\n",
    "    # Initialize the Census API with the provided key\n",
    "    c = Census(census_api_key)\n",
    "\n",
    "    census_pop = []\n",
    "\n",
    "    # Retrieve census data by block group for the specified state and county\n",
    "    for county_fip in county_fips:\n",
    "        data = c.acs5.state_county_blockgroup('B01003_001E', state_fips, county_fip, Census.ALL, year=year)\n",
    "        census_pop.extend(data)\n",
    "\n",
    "    # Convert the retrieved population data to a DataFrame and add an index to align with census_gdf\n",
    "    census_pop_df = pd.DataFrame(census_pop)\n",
    "    census_pop_df['index'] = census_pop_df.index  # Add an index column to match order\n",
    "\n",
    "    print(f\"Data retrieved from the Census API (first few rows):\\n{census_pop_df.head()}\")\n",
    "\n",
    "    # Rename columns in census_gdf to match the names in census_pop_df\n",
    "    census_gdf.rename(columns={\n",
    "        'STATEFP': 'state',\n",
    "        'COUNTYFP': 'county',\n",
    "        'TRACTCE': 'tract',\n",
    "        'BLKGRPCE': 'block group'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add an index column to census_gdf as well to ensure we can align by index\n",
    "    census_gdf['index'] = census_gdf.index\n",
    "    print(f\"First few rows of the GeoDataFrame (census_gdf):\\n{census_gdf[['index', 'state', 'county', 'tract', 'block group']].head()}\")\n",
    "\n",
    "    # Merge census_gdf with the population DataFrame by the 'index' column to ensure order-based merging\n",
    "    merged_gdf = census_gdf.merge(census_pop_df[['index', 'B01003_001E']], on='index', how='left')\n",
    "\n",
    "    # Drop the index column as it's no longer needed\n",
    "    merged_gdf = merged_gdf.drop(columns=['index'])\n",
    "\n",
    "    # Rename the population column to something more user-friendly\n",
    "    merged_gdf.rename(columns={'B01003_001E': 'Population Count'}, inplace=True)\n",
    "\n",
    "    # Create the 'GEOID' column\n",
    "    merged_gdf['GEOID'] = merged_gdf['state'] + merged_gdf['county'] + merged_gdf['tract'] + merged_gdf['block group']\n",
    "\n",
    "    # Calculate area in square kilometers\n",
    "    area_sqkm = merged_gdf['ALAND'] / 10**6\n",
    "    merged_gdf['Polygon Area'] = area_sqkm\n",
    "\n",
    "    # Calculate population density\n",
    "    merged_gdf['Population Density'] = merged_gdf['Population Count'] / area_sqkm\n",
    "\n",
    "    # Calculate PDI (Population Density Index) as a percentage of the max density\n",
    "    max_density = merged_gdf['Population Density'].max() if not merged_gdf['Population Density'].isna().all() else 1\n",
    "    merged_gdf['PDI'] = (merged_gdf['Population Density'] / max_density) * 100  # PDI as percentage of max, ranging from 0 to 100\n",
    "\n",
    "    # Calculate centroids and extract coordinates\n",
    "    merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n",
    "    merged_gdf['Coordinates'] = merged_gdf['Centroid'].apply(lambda x: f\"({x.y:.6f}, {x.x:.6f})\")\n",
    "\n",
    "    # Drop the Centroid column before saving to GeoJSON\n",
    "    merged_gdf = merged_gdf.drop(columns=['Centroid'])\n",
    "\n",
    "    # Save processed data to GeoJSON\n",
    "    merged_gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    # Prepare CSV output with specified column names and order\n",
    "    csv_output = merged_gdf[['GEOID', 'Population Count', 'Population Density', 'PDI', 'Polygon Area', 'Coordinates']]\n",
    "    csv_output.to_csv(csv_output_file, index=False)\n",
    "    print(f\"CSV data saved to {csv_output_file}\")\n",
    "    \n",
    "    # Append population density to aggregate file\n",
    "    geoidandyear = census_gdf[\"GEOID\"] + \"+\" + str(year)\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Population Density\": census_gdf[\"Population Density\"]\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode='w', header=True, index=False)\n",
    "\n",
    "    return merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c080e83-04ef-431e-8476-085568d0087c",
   "metadata": {
    "id": "3c080e83-04ef-431e-8476-085568d0087c"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "import os\n",
    "\n",
    "def get_tract_population(census_gdf, census_api_key, year, output_file, csv_output_file, aggregate_file):\n",
    "    \"\"\"\n",
    "    Retrieves population data for block groups based on a given year and saves the processed data to a file.\n",
    "\n",
    "    Parameters:\n",
    "        census_gdf (GeoDataFrame): The GeoDataFrame containing the geometries for the census block groups.\n",
    "        census_api_key (str): The Census API key.\n",
    "        year (int): The year for which the data is retrieved (e.g., 2013, 2022).\n",
    "        output_file (str): The filename where the processed data will be saved.\n",
    "        csv_output_file (str): The filename for saving the processed CSV data.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the processed data to the specified files.\n",
    "    \"\"\"\n",
    "    # Check if the API key is provided\n",
    "    if not census_api_key:\n",
    "        raise ValueError(\"API key must be provided as the 'census_api_key' parameter.\")\n",
    "\n",
    "    # Gets state and county FIPS codes\n",
    "    state_fips = census_gdf.STATEFP[0]\n",
    "    county_fips = census_gdf.COUNTYFP.unique()\n",
    "\n",
    "    # Initialize the Census API with the provided key\n",
    "    c = Census(census_api_key)\n",
    "\n",
    "    census_pop = []\n",
    "\n",
    "    # Retrieve census data by block group for the specified state and county\n",
    "    for county_fip in county_fips:\n",
    "        data = c.acs5.state_county_blockgroup('B01003_001E', state_fips, county_fip, Census.ALL, year=year)\n",
    "        census_pop.extend(data)\n",
    "\n",
    "    # Convert the retrieved population data to a DataFrame and add an index to align with census_gdf\n",
    "    census_pop_df = pd.DataFrame(census_pop)\n",
    "    census_pop_df['index'] = census_pop_df.index  # Add an index column to match order\n",
    "\n",
    "    print(f\"Data retrieved from the Census API (first few rows):\\n{census_pop_df.head()}\")\n",
    "\n",
    "    # Rename columns in census_gdf to match the names in census_pop_df\n",
    "    census_gdf.rename(columns={\n",
    "        'STATEFP': 'state',\n",
    "        'COUNTYFP': 'county',\n",
    "        'TRACTCE': 'tract',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add an index column to census_gdf as well to ensure we can align by index\n",
    "    census_gdf['index'] = census_gdf.index\n",
    "\n",
    "    # Merge census_gdf with the population DataFrame by the 'index' column to ensure order-based merging\n",
    "    merged_gdf = census_gdf.merge(census_pop_df[['index', 'B01003_001E']], on='index', how='left')\n",
    "\n",
    "    # Drop the index column as it's no longer needed\n",
    "    merged_gdf = merged_gdf.drop(columns=['index'])\n",
    "\n",
    "    # Rename the population column to something more user-friendly\n",
    "    merged_gdf.rename(columns={'B01003_001E': 'Population Count'}, inplace=True)\n",
    "\n",
    "    # Create the 'GEOID' column\n",
    "    merged_gdf['GEOID'] = merged_gdf['state'] + merged_gdf['county'] + merged_gdf['tract'] \n",
    "\n",
    "    # Calculate area in square kilometers\n",
    "    area_sqkm = merged_gdf['ALAND'] / 10**6\n",
    "    merged_gdf['Polygon Area'] = area_sqkm\n",
    "\n",
    "    # Calculate population density\n",
    "    merged_gdf['Population Density'] = merged_gdf['Population Count'] / area_sqkm\n",
    "\n",
    "    # Calculate PDI (Population Density Index) as a percentage of the max density\n",
    "    max_density = merged_gdf['Population Density'].max() if not merged_gdf['Population Density'].isna().all() else 1\n",
    "    merged_gdf['PDI'] = (merged_gdf['Population Density'] / max_density) * 100  # PDI as percentage of max, ranging from 0 to 100\n",
    "\n",
    "    # Ensure that merged_gdf has a valid geometry\n",
    "    merged_gdf = gpd.GeoDataFrame(merged_gdf, geometry='geometry')\n",
    "\n",
    "    # Calculate centroids and extract coordinates\n",
    "    merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n",
    "    merged_gdf['Coordinates'] = merged_gdf['Centroid'].apply(lambda x: f\"({x.y:.6f}, {x.x:.6f})\")\n",
    "\n",
    "    # Drop the Centroid column before saving to GeoJSON\n",
    "    merged_gdf = merged_gdf.drop(columns=['Centroid'])\n",
    "\n",
    "    # Save processed data to GeoJSON\n",
    "    merged_gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    # Prepare CSV output with specified column names and order\n",
    "    csv_output = merged_gdf[['GEOID', 'Population Count', 'Population Density', 'PDI', 'Polygon Area', 'Coordinates']]\n",
    "    csv_output.to_csv(csv_output_file, index=False)\n",
    "    print(f\"CSV data saved to {csv_output_file}\")\n",
    "    \n",
    "    # Append population density to aggregate file\n",
    "    geoidandyear = merged_gdf[\"GEOID\"] + \"+\" + str(year)\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Population Density\": merged_gdf[\"Population Density\"]\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode='w', header=True, index=False)\n",
    "\n",
    "    return merged_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c14c198b-78a9-4355-bfa6-ca035a2baba1",
   "metadata": {
    "id": "c14c198b-78a9-4355-bfa6-ca035a2baba1"
   },
   "outputs": [],
   "source": [
    "# Tract execution\n",
    "census_gdf = gpd.read_file('tracts.geojson')\n",
    "census_api_key = \"bb8ddb8b99dc18f4759d67d905c25e1486077c4d\"  # Provide your API key here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e993e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from the Census API (first few rows):\n",
      "   B01003_001E state county   tract block group  index\n",
      "0        838.0    06    077  001200           3      0\n",
      "1       1249.0    06    077  001200           4      1\n",
      "2       2269.0    06    077  001200           1      2\n",
      "3       1261.0    06    077  001400           4      3\n",
      "4       1150.0    06    077  001400           2      4\n",
      "First few rows of the GeoDataFrame (census_gdf):\n",
      "   index state county   tract\n",
      "0      0    06    077  005127\n",
      "1      1    06    077  003406\n",
      "2      2    06    077  004402\n",
      "3      3    06    077  001700\n",
      "4      4    06    077  000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_22852\\437821030.py:82: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tracts_2017_PDI.geojson\n",
      "CSV data saved to tracts_2017_PDI.csv\n"
     ]
    }
   ],
   "source": [
    "census_gdf_2017 = get_tract_population(\n",
    "    census_gdf, year=2017, census_api_key=census_api_key,\n",
    "    output_file=\"tracts_2017_PDI.geojson\", #INSERT FILES\n",
    "    csv_output_file=\"tracts_2017_PDI.csv\",\n",
    "    aggregate_file=\"PDI_tract_all.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fac89a92-9e50-4f99-be2a-1649b796b1b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fac89a92-9e50-4f99-be2a-1649b796b1b7",
    "outputId": "a4ba0141-ae5f-4cc9-dba7-2d3d27ed085a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from the Census API (first few rows):\n",
      "   B01003_001E state county   tract block group  index\n",
      "0       2200.0    06    077  005004           2      0\n",
      "1       1698.0    06    077  005403           3      1\n",
      "2       1721.0    06    077  005403           4      2\n",
      "3       2692.0    06    077  005210           2      3\n",
      "4       7434.0    06    077  005210           1      4\n",
      "First few rows of the GeoDataFrame (census_gdf):\n",
      "   index state county   tract\n",
      "0      0    06    077  005127\n",
      "1      1    06    077  003406\n",
      "2      2    06    077  004402\n",
      "3      3    06    077  001700\n",
      "4      4    06    077  000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_22852\\437821030.py:82: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tracts_2013_PDI.geojson\n",
      "CSV data saved to tracts_2013_PDI.csv\n"
     ]
    }
   ],
   "source": [
    "# Process population data for both years and save as CSV for tracts\n",
    "census_gdf = gpd.read_file('tracts.geojson')\n",
    "census_gdf_2013 = get_tract_population(\n",
    "    census_gdf, year=2013, census_api_key=census_api_key,\n",
    "    output_file=\"tracts_2013_PDI.geojson\", #INSERT FILES\n",
    "    csv_output_file=\"tracts_2013_PDI.csv\",\n",
    "    aggregate_file=\"PDI_tract_all.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ea9cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from the Census API (first few rows):\n",
      "   B01003_001E state county   tract block group  index\n",
      "0        606.0    06    077  000101           1      0\n",
      "1       1043.0    06    077  000101           2      1\n",
      "2        502.0    06    077  000102           1      2\n",
      "3       1118.0    06    077  000102           2      3\n",
      "4        393.0    06    077  000102           3      4\n",
      "First few rows of the GeoDataFrame (census_gdf):\n",
      "   index state county   tract\n",
      "0      0    06    077  005127\n",
      "1      1    06    077  003406\n",
      "2      2    06    077  004402\n",
      "3      3    06    077  001700\n",
      "4      4    06    077  000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_22852\\437821030.py:82: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tracts_2022_PDI.geojson\n",
      "CSV data saved to tracts_2022_PDI.csv\n"
     ]
    }
   ],
   "source": [
    "census_gdf = gpd.read_file('tracts.geojson')\n",
    "census_gdf_2022 = get_tract_population(\n",
    "    census_gdf, year=2022, census_api_key=census_api_key,\n",
    "    output_file=\"tracts_2022_PDI.geojson\", #INSERT FILES\n",
    "    csv_output_file=\"tracts_2022_PDI.csv\",\n",
    "    aggregate_file=\"PDI_tract_all.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
